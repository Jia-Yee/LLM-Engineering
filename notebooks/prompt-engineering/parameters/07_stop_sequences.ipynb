{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba5764a",
   "metadata": {},
   "source": [
    "# Stop Sequences Parameter in LLMs\n",
    "\n",
    "## Introduction\n",
    "Stop sequences are specific strings that tell the model when to stop generating text. They act as termination signals, allowing fine-grained control over where the model's output should end.\n",
    "\n",
    "Key aspects:\n",
    "- **Format**: Can be single characters, words, or phrases\n",
    "- **Multiple stops**: Can specify multiple stop sequences\n",
    "- **Case sensitivity**: Usually case-sensitive\n",
    "- **Whitespace**: Handling depends on implementation\n",
    "\n",
    "Understanding stop sequences is crucial for:\n",
    "- Controlling output boundaries\n",
    "- Maintaining format consistency\n",
    "- Implementing structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7848c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def query_ollama(prompt, stop=None):\n",
    "    \"\"\"Query Ollama with specific stop sequences\"\"\"\n",
    "    cmd = [\n",
    "        \"curl\",\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        \"-d\",\n",
    "        json.dumps({\n",
    "            \"model\": \"llama2\",\n",
    "            \"prompt\": prompt,\n",
    "            \"stop\": stop if stop else []\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    output, _ = process.communicate()\n",
    "\n",
    "    responses = [json.loads(line) for line in output.decode().strip().split(\"\\n\")]\n",
    "    return \"\".join(r.get(\"response\", \"\") for r in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee71f5",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Let's explore how different stop sequences affect the model's output. We'll use various prompts and stop sequences to demonstrate their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = \"List the first 5 planets from the sun:\\n1. Mercury\\n2. Venus\\n3.\"\n",
    "\n",
    "print(\"No stop sequence:\")\n",
    "print(query_ollama(list_prompt))\n",
    "print(\"\\nStop at newline ('\\n'):\")\n",
    "print(query_ollama(list_prompt, stop=[\"\\n\"]))\n",
    "print(\"\\nStop at number ('4.'):\")\n",
    "print(query_ollama(list_prompt, stop=[\"4.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = \"Q: What is machine learning?\\nA: \"\n",
    "\n",
    "print(\"Stop at next question ('Q:'):\")\n",
    "print(query_ollama(qa_prompt, stop=[\"Q:\"]))\n",
    "print(\"\\nStop at multiple sequences ('Q:' or '\\n'):\")\n",
    "print(query_ollama(qa_prompt, stop=[\"Q:\", \"\\n\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d654cb",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Choose stop sequences based on your use case:\n",
    "\n",
    "1. **Structured Output**\n",
    "   - Use delimiters like `###` or `===`\n",
    "   - Consider using unique tokens\n",
    "   - Match start/end patterns\n",
    "\n",
    "2. **Conversational**\n",
    "   - Use turn indicators (`User:`, `Assistant:`)\n",
    "   - Consider newlines as stops\n",
    "   - Use clear dialogue markers\n",
    "\n",
    "3. **List Generation**\n",
    "   - Use numbering patterns\n",
    "   - Consider item separators\n",
    "   - Use consistent formatting\n",
    "\n",
    "**Tips:**\n",
    "- Keep stop sequences unique and unambiguous\n",
    "- Test stop sequences with sample outputs\n",
    "- Consider case sensitivity\n",
    "- Use multiple stop sequences when needed\n",
    "- Be careful with common words as stops\n",
    "- Document stop sequences for reproducibility"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
