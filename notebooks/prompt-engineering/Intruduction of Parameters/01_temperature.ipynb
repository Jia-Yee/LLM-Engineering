{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32cd651",
   "metadata": {},
   "source": [
    "# Temperature Parameter in LLMs\n",
    "\n",
    "## Introduction\n",
    "Temperature is a crucial parameter in Large Language Models that controls the randomness and creativity of the model's outputs. It is typically set between 0 and 1, where:\n",
    "\n",
    "- **Temperature = 0**: The model becomes deterministic, always choosing the most likely next token\n",
    "- **Temperature = 1**: The model maintains the original probability distribution\n",
    "- **Temperature > 1**: The model increases randomness, making all token probabilities more uniform\n",
    "\n",
    "Think of temperature as a \"creativity knob\" - lower values make the model more focused and consistent, while higher values make it more creative and diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6007b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def query_ollama(prompt, temperature=0.7):\n",
    "    \"\"\"Query Ollama with a specific temperature setting\"\"\"\n",
    "    cmd = [\n",
    "        \"curl\",\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        \"-d\",\n",
    "        json.dumps({\n",
    "            \"model\": \"llama3\",\n",
    "            \"prompt\": prompt,\n",
    "            \"options\": { \"temperature\": temperature }\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    output, _ = process.communicate()\n",
    "\n",
    "    responses = [json.loads(line) for line in output.decode().strip().split(\"\\n\")]\n",
    "    return \"\".join(r.get(\"response\", \"\") for r in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc9c7e",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Let's explore how different temperature values affect the model's output. We'll use a creative writing prompt and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a453bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.0 (Very focused)\n",
      "As I wandered through the ancient forest, my curiosity got the better of me and I pushed open the creaky door hidden behind a screen of vines and leaves, revealing a room filled with dusty tomes and whispering shadows that seemed to hold secrets only meant for me.\n",
      "\n",
      "Temperature = 0.7 (Balanced)\n",
      "As I wandered through the ancient forest, I stumbled upon a weathered wooden door hidden behind a veil of vines and moss, its intricate carvings seeming to whisper secrets only meant for those brave enough to turn the rusty doorknob and step into the unknown beyond.\n",
      "\n",
      "Temperature = 1.5 (Very creative)\n",
      "As I wandered deeper into the ancient forest, the whispers of the trees grew hushed and the rustling of leaves ceased as I stumbled upon a door, its weathered wooden slats adorned with strange symbols that seemed to pulse with an otherworldly energy, beckoning me closer with an irresistible whisper: \"Come inside, where secrets await.\"\n"
     ]
    }
   ],
   "source": [
    "creative_prompt = \"Write a one-sentence story about a mysterious door in the forest.\"\n",
    "\n",
    "print(\"Temperature = 0.0 (Very focused)\")\n",
    "print(query_ollama(creative_prompt, temperature=0.0))\n",
    "print(\"\\nTemperature = 0.7 (Balanced)\")\n",
    "print(query_ollama(creative_prompt, temperature=0.7))\n",
    "print(\"\\nTemperature = 1.5 (Very creative)\")\n",
    "print(query_ollama(creative_prompt, temperature=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed853c4",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Choose temperature based on your use case:\n",
    "\n",
    "1. **Low Temperature (0.0 - 0.3)**\n",
    "   - Fact-based QA\n",
    "   - Code generation\n",
    "   - Logic problems\n",
    "   - When consistency is crucial\n",
    "\n",
    "2. **Medium Temperature (0.4 - 0.7)**\n",
    "   - General conversation\n",
    "   - Text summarization\n",
    "   - Most default use cases\n",
    "\n",
    "3. **High Temperature (0.8 - 1.5)**\n",
    "   - Creative writing\n",
    "   - Brainstorming\n",
    "   - Generating diverse ideas\n",
    "   - When uniqueness is valued\n",
    "\n",
    "Remember: Higher temperature values increase diversity but may also increase the likelihood of errors or hallucinations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
