{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b290ed74",
   "metadata": {},
   "source": [
    "# Basic LLM Parameters for Recruitment Tasks\n",
    "\n",
    "This notebook covers the fundamental parameters for controlling LLM outputs in recruitment contexts:\n",
    "\n",
    "1. Temperature - Controls randomness and creativity\n",
    "2. Top-p (Nucleus Sampling) - Controls diversity of token selection\n",
    "3. Top-k - Limits the number of tokens considered\n",
    "4. Max Tokens - Controls response length\n",
    "\n",
    "We'll explore how these parameters affect different recruitment tasks including:\n",
    "- Job description generation and analysis\n",
    "- Resume parsing and evaluation\n",
    "- Company information processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5d1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def query_model(prompt, **params):\n",
    "    \"\"\"Query the Ollama API with specified parameters.\"\"\"\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3',\n",
    "            'prompt': prompt,\n",
    "            **params\n",
    "        }\n",
    "    )\n",
    "    return response.json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1a1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def query_model(prompt, **params):\n",
    "    \"\"\"Query Ollama with a specific presence_penalty setting\"\"\"\n",
    "    cmd = [\n",
    "        \"curl\",\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        \"-d\",\n",
    "        json.dumps({\n",
    "            \"model\": \"llama2\",\n",
    "            \"prompt\": prompt,\n",
    "            **params\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    output, _ = process.communicate()\n",
    "\n",
    "    responses = [json.loads(line) for line in output.decode().strip().split(\"\\n\")]\n",
    "    return \"\".join(r.get(\"response\", \"\") for r in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58485ed1",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "Understanding temperature in recruitment contexts:\n",
    "- How it affects output quality\n",
    "- Best practices for different tasks\n",
    "- Example scenarios and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49f0fa",
   "metadata": {},
   "source": [
    "### Job Description\n",
    "\n",
    "Testing temperature with this recruiting scenario:\n",
    "```\n",
    "Write a job description for a Senior Software Engineer position focusing on AI/ML development.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e86b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature = 0.1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response:**\n",
       "\n",
       "Job Title: Senior Software Engineer - AI/ML Development\n",
       "\n",
       "Job Summary:\n",
       "We are seeking an experienced and highly skilled Senior Software Engineer to join our team focused on the development of artificial intelligence (AI) and machine learning (ML) applications. The successful candidate will be responsible for leading the design, development, testing, and deployment of AI/ML models and software, as well as collaborating with cross-functional teams to identify and prioritize project requirements. This is a full-time position located in [insert location].\n",
       "\n",
       "Responsibilities:\n",
       "\n",
       "* Design, develop, test, and deploy AI/ML models and software using various programming languages and frameworks (e.g., Python, TensorFlow, PyTorch)\n",
       "* Collaborate with cross-functional teams to identify and prioritize project requirements\n",
       "* Develop and maintain documentation of AI/ML architectures and algorithms\n",
       "* Conduct code reviews and provide constructive feedback to junior team members\n",
       "* Stay up-to-date with industry trends and best practices in AI/ML development\n",
       "* Work closely with data scientists and other stakeholders to integrate AI/ML models into larger systems\n",
       "* Participate in the full software development lifecycle, including requirement gathering, design, implementation, testing, and deployment\n",
       "* Collaborate with external partners and vendors to incorporate their AI/ML offerings into our products and services\n",
       "* Mentor and train junior engineers on AI/ML techniques and best practices\n",
       "\n",
       "Requirements:\n",
       "\n",
       "* Bachelor's degree in Computer Science, Machine Learning, or related field (Master's degree preferred)\n",
       "* At least 5 years of experience in AI/ML development, with a focus on software engineering\n",
       "* Strong proficiency in programming languages such as Python, Java, C++, or MATLAB\n",
       "* Experience with popular ML frameworks such as TensorFlow, PyTorch, or Scikit-learn\n",
       "* Familiarity with data science tools and libraries such as NumPy, Pandas, or Matplotlib\n",
       "* Strong understanding of software development principles, patterns, and best practices\n",
       "* Experience working with large datasets and distributing computing environments (e.g., Hadoop, Spark)\n",
       "* Excellent communication and collaboration skills\n",
       "\n",
       "Preferred Qualifications:\n",
       "\n",
       "* Master's degree in Computer Science, Machine Learning, or related field\n",
       "* Experience with cloud-based AI/ML platforms (e.g., AWS SageMaker, Google Cloud AI Platform)\n",
       "* Familiarity with DevOps practices and tools (e.g., Jenkins, Docker)\n",
       "* Experience with data visualization libraries such as Matplotlib or Seaborn\n",
       "* Knowledge of database systems and data modeling techniques\n",
       "* Familiarity with security and privacy considerations in AI/ML development\n",
       "\n",
       "We Offer:\n",
       "\n",
       "* Competitive salary and benefits package\n",
       "* Opportunities for professional growth and career advancement\n",
       "* Collaborative and dynamic work environment with a passionate team of engineers and scientists\n",
       "* Flexible work arrangements and remote work options\n",
       "* Access to cutting-edge technologies and tools in the field of AI/ML\n",
       "\n",
       "How to Apply:\n",
       "If you are an experienced software engineer with a passion for AI/ML development, please submit your resume and cover letter to [insert contact information]. We look forward to hearing from you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature = 0.5\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response:**\n",
       "\n",
       "Job Title: Senior Software Engineer - AI/ML Development\n",
       "\n",
       "Job Summary:\n",
       "We are seeking an experienced and highly skilled Senior Software Engineer to join our team focused on the development of artificial intelligence (AI) and machine learning (ML) solutions. The successful candidate will be responsible for designing, developing, and deploying cutting-edge AI/ML models and algorithms that drive business outcomes for our clients. This is a full-time position located in [City, State].\n",
       "\n",
       "Key Responsibilities:\n",
       "\n",
       "* Design and develop complex AI/ML models and algorithms to solve real-world problems.\n",
       "* Work closely with cross-functional teams, including data scientists, data engineers, and business stakeholders to identify opportunities for AI/ML adoption.\n",
       "* Develop and maintain robust, scalable, and secure software applications using modern programming languages and frameworks.\n",
       "* Collaborate with other software engineers to ensure the development of high-quality, maintainable code that meets industry standards.\n",
       "* Stay up-to-date with the latest advancements in AI/ML research and technologies to identify opportunities for innovation and improvement.\n",
       "* Analyze and interpret complex data sets to inform AI/ML model development.\n",
       "* Communicate technical findings and insights effectively to both technical and non-technical audiences.\n",
       "* Collaborate with data scientists to develop and deploy AI/ML models that drive business outcomes.\n",
       "\n",
       "Requirements:\n",
       "\n",
       "* Bachelor's or Master's degree in Computer Science, Machine Learning, or related field.\n",
       "* At least 5 years of experience in software development, with a focus on AI/ML.\n",
       "* Strong proficiency in programming languages such as Python, Java, C++, and R.\n",
       "* Experience with ML frameworks and libraries such as TensorFlow, PyTorch, or Scikit-learn.\n",
       "* Familiarity with database systems and data modeling.\n",
       "* Excellent problem-solving skills and ability to work independently and collaboratively.\n",
       "* Strong communication and interpersonal skills.\n",
       "* Experience with cloud computing platforms such as AWS or GCP.\n",
       "\n",
       "Preferred Qualifications:\n",
       "\n",
       "* Advanced degree in Computer Science, Machine Learning, or related field.\n",
       "* Experience with AI/ML model deployment and management in production environments.\n",
       "* Familiarity with containerization technologies such as Docker.\n",
       "* Experience with Agile software development methodologies.\n",
       "* Knowledge of data privacy and security best practices.\n",
       "\n",
       "What We Offer:\n",
       "\n",
       "* Competitive salary and benefits package.\n",
       "* Opportunities for career growth and professional development.\n",
       "* Collaborative and dynamic work environment with a diverse team of professionals.\n",
       "* Flexible working hours and remote work options.\n",
       "* Access to cutting-edge technologies and tools.\n",
       "\n",
       "How to Apply:\n",
       "If you are passionate about AI/ML development and have a track record of building innovative solutions, please submit your resume and cover letter to [Contact Information]. We can't wait to hear from you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature = 0.9\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response:**\n",
       "\n",
       "Job Title: Senior Software Engineer - AI/ML Development\n",
       "\n",
       "Job Summary:\n",
       "We are seeking an experienced and highly skilled Senior Software Engineer to join our team focused on the development of artificial intelligence (AI) and machine learning (ML) systems. The successful candidate will be responsible for designing, implementing, and maintaining large-scale AI/ML applications and systems, as well as mentoring junior engineers and contributing to the overall success of the team.\n",
       "\n",
       "Responsibilities:\n",
       "\n",
       "* Design, develop, and deploy large-scale AI/ML systems using a variety of programming languages, frameworks, and tools such as Python, TensorFlow, PyTorch, Keras, etc.\n",
       "* Collaborate with cross-functional teams to identify and prioritize project requirements and create solution designs.\n",
       "* Develop and maintain high-quality codebase by following best practices for engineering, testing, and debugging.\n",
       "* Stay up-to-date with the latest advancements in AI/ML and related technologies and incorporate them into development projects as appropriate.\n",
       "* Mentor junior engineers and provide technical guidance to ensure successful project delivery.\n",
       "* Work closely with data scientists and other stakeholders to develop and deploy ML models that meet business requirements.\n",
       "* Participate in code reviews, design discussions, and sprint planning to ensure the success of the project.\n",
       "* Write clean, readable, and maintainable code that adheres to industry standards and best practices.\n",
       "* Collaborate with other teams such as data science, product management, and UX/UI to deliver high-quality AI/ML solutions.\n",
       "* Stay abreast of industry trends and emerging technologies in the field of AI/ML.\n",
       "\n",
       "Requirements:\n",
       "\n",
       "* Bachelor's degree in Computer Science or related field.\n",
       "* At least 5 years of experience in software development with a focus on AI/ML.\n",
       "* Strong programming skills in languages such as Python, Java, C++, etc.\n",
       "* Experience with popular ML frameworks such as TensorFlow, PyTorch, Keras, etc.\n",
       "* Knowledge of machine learning algorithms and models, including deep learning.\n",
       "* Experience working with large datasets and distributed computing environments.\n",
       "* Excellent problem-solving skills and attention to detail.\n",
       "* Strong communication and collaboration skills.\n",
       "* Familiarity with Agile development methodologies and version control systems such as Git.\n",
       "\n",
       "Preferred Qualifications:\n",
       "\n",
       "* Master's degree in Computer Science or related field.\n",
       "* Experience working in a fast-paced, dynamic environment.\n",
       "* Knowledge of cloud computing platforms such as AWS, GCP, etc.\n",
       "* Experience with DevOps tools and practices.\n",
       "* Familiarity with data science workflows and ML model deployment.\n",
       "* Experience working with cross-functional teams to deliver AI/ML solutions.\n",
       "\n",
       "We Offer:\n",
       "\n",
       "* Competitive salary and benefits package.\n",
       "* Opportunities for career growth and professional development.\n",
       "* Collaborative and dynamic work environment.\n",
       "* Flexible work arrangements, including remote work options.\n",
       "* Access to cutting-edge AI/ML technologies and tools.\n",
       "\n",
       "How to Apply:\n",
       "If you are passionate about AI/ML development and have a track record of delivering high-quality software solutions, we encourage you to apply for this exciting opportunity. Please submit your resume and cover letter to [insert contact information]. We look forward to hearing from you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try different temperature values\n",
    "for value in [0.1, 0.5, 0.9]:\n",
    "    print(f\"\\ntemperature = {value}\")\n",
    "    response = query_model('''Write a job description for a Senior Software Engineer position focusing on AI/ML development.''', temperature=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3bc7b",
   "metadata": {},
   "source": [
    "### Resume Summary\n",
    "\n",
    "Testing temperature with this recruiting scenario:\n",
    "```\n",
    "Summarize a resume that highlights 5 years of Python development, ML model deployment, and team leadership.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22e1a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature = 0.1\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 94)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/models.py:963\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/simplejson/__init__.py:525\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    522\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    523\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_decimal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/simplejson/decoder.py:373\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end, \u001b[38;5;28mlen\u001b[39m(s))\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 - line 508 column 1 (char 94 - 51680)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtemperature = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43mSummarize a resume that highlights 5 years of Python development, ML model deployment, and team leadership.\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Response:**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mquery_model\u001b[0;34m(prompt, **params)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query the Ollama API with specified parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:11434/api/generate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     json\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 971\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 94)"
     ]
    }
   ],
   "source": [
    "# Try different temperature values\n",
    "for value in [0.1, 0.5, 0.9]:\n",
    "    print(f\"\\ntemperature = {value}\")\n",
    "    response = query_model('''Summarize a resume that highlights 5 years of Python development, ML model deployment, and team leadership.''', temperature=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89005d4b",
   "metadata": {},
   "source": [
    "### Company Culture\n",
    "\n",
    "Testing temperature with this recruiting scenario:\n",
    "```\n",
    "Describe the company culture of a fast-growing AI startup.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different temperature values\n",
    "for value in [0.1, 0.5, 0.9]:\n",
    "    print(f\"\\ntemperature = {value}\")\n",
    "    response = query_model('''Describe the company culture of a fast-growing AI startup.''', temperature=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e90784",
   "metadata": {},
   "source": [
    "## Top_P\n",
    "\n",
    "Understanding top_p in recruitment contexts:\n",
    "- How it affects output quality\n",
    "- Best practices for different tasks\n",
    "- Example scenarios and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086ae27",
   "metadata": {},
   "source": [
    "### Skill Matching\n",
    "\n",
    "Testing top_p with this recruiting scenario:\n",
    "```\n",
    "Given a job requirement for 'Python, TensorFlow, and AWS experience', analyze if a candidate with 'extensive Python, PyTorch background, and GCP expertise' is a good match.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_p values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_p = {value}\")\n",
    "    response = query_model('''Given a job requirement for 'Python, TensorFlow, and AWS experience', analyze if a candidate with 'extensive Python, PyTorch background, and GCP expertise' is a good match.''', top_p=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af62a93",
   "metadata": {},
   "source": [
    "### Candidate Evaluation\n",
    "\n",
    "Testing top_p with this recruiting scenario:\n",
    "```\n",
    "Evaluate a software engineer candidate based on: 5 years Python, 3 years ML deployment, team lead experience.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_p values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_p = {value}\")\n",
    "    response = query_model('''Evaluate a software engineer candidate based on: 5 years Python, 3 years ML deployment, team lead experience.''', top_p=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8114baa",
   "metadata": {},
   "source": [
    "### Role Requirements\n",
    "\n",
    "Testing top_p with this recruiting scenario:\n",
    "```\n",
    "List the key requirements for a Machine Learning Engineer position.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_p values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_p = {value}\")\n",
    "    response = query_model('''List the key requirements for a Machine Learning Engineer position.''', top_p=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa024a94",
   "metadata": {},
   "source": [
    "## Top_K\n",
    "\n",
    "Understanding top_k in recruitment contexts:\n",
    "- How it affects output quality\n",
    "- Best practices for different tasks\n",
    "- Example scenarios and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c64b4",
   "metadata": {},
   "source": [
    "### Technical Skills\n",
    "\n",
    "Testing top_k with this recruiting scenario:\n",
    "```\n",
    "Extract and categorize technical skills from this resume snippet: 'Developed ML models using TensorFlow, deployed on AWS, managed team of 5 engineers'.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_k values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_k = {value}\")\n",
    "    response = query_model('''Extract and categorize technical skills from this resume snippet: 'Developed ML models using TensorFlow, deployed on AWS, managed team of 5 engineers'.''', top_k=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b30a97f",
   "metadata": {},
   "source": [
    "### Job Categories\n",
    "\n",
    "Testing top_k with this recruiting scenario:\n",
    "```\n",
    "Classify this job posting into relevant categories: 'Senior ML Engineer with focus on NLP and large language models'.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_k values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_k = {value}\")\n",
    "    response = query_model('''Classify this job posting into relevant categories: 'Senior ML Engineer with focus on NLP and large language models'.''', top_k=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84dafdd",
   "metadata": {},
   "source": [
    "### Experience Level\n",
    "\n",
    "Testing top_k with this recruiting scenario:\n",
    "```\n",
    "Determine the experience level from: '7 years building production ML systems, leading teams of 3-8 engineers'.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different top_k values\n",
    "for value in [10, 40, 100]:\n",
    "    print(f\"\\ntop_k = {value}\")\n",
    "    response = query_model('''Determine the experience level from: '7 years building production ML systems, leading teams of 3-8 engineers'.''', top_k=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e5e0c",
   "metadata": {},
   "source": [
    "## Max_Tokens\n",
    "\n",
    "Understanding max_tokens in recruitment contexts:\n",
    "- How it affects output quality\n",
    "- Best practices for different tasks\n",
    "- Example scenarios and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef509928",
   "metadata": {},
   "source": [
    "### Short Summary\n",
    "\n",
    "Testing max_tokens with this recruiting scenario:\n",
    "```\n",
    "Create a one-sentence summary of this job posting: 'We're seeking a Senior ML Engineer to lead our NLP team, focusing on large language model development and deployment. The ideal candidate has 5+ years of experience in Python, deep learning frameworks, and production ML systems.'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f97358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different max_tokens values\n",
    "for value in [50, 150, 300]:\n",
    "    print(f\"\\nmax_tokens = {value}\")\n",
    "    response = query_model('''Create a one-sentence summary of this job posting: 'We're seeking a Senior ML Engineer to lead our NLP team, focusing on large language model development and deployment. The ideal candidate has 5+ years of experience in Python, deep learning frameworks, and production ML systems.'''', max_tokens=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ff62c",
   "metadata": {},
   "source": [
    "### Detailed Analysis\n",
    "\n",
    "Testing max_tokens with this recruiting scenario:\n",
    "```\n",
    "Provide a detailed analysis of this candidate's qualifications: 'ML Engineer with 6 years experience in Python, TensorFlow, and AWS. Led team of 5 engineers, deployed 10+ ML models to production. PhD in Computer Science with focus on NLP.'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92358b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different max_tokens values\n",
    "for value in [50, 150, 300]:\n",
    "    print(f\"\\nmax_tokens = {value}\")\n",
    "    response = query_model('''Provide a detailed analysis of this candidate's qualifications: 'ML Engineer with 6 years experience in Python, TensorFlow, and AWS. Led team of 5 engineers, deployed 10+ ML models to production. PhD in Computer Science with focus on NLP.'''', max_tokens=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b0cd4",
   "metadata": {},
   "source": [
    "### Company Overview\n",
    "\n",
    "Testing max_tokens with this recruiting scenario:\n",
    "```\n",
    "Generate a company overview of varying lengths for an AI startup specializing in recruitment technology.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different max_tokens values\n",
    "for value in [50, 150, 300]:\n",
    "    print(f\"\\nmax_tokens = {value}\")\n",
    "    response = query_model('''Generate a company overview of varying lengths for an AI startup specializing in recruitment technology.''', max_tokens=value)\n",
    "    display(Markdown(f\"**Response:**\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9822717",
   "metadata": {},
   "source": [
    "## Best Practices Summary\n",
    "\n",
    "When working with basic parameters in recruitment:\n",
    "\n",
    "1. Temperature (Creativity vs. Consistency)\n",
    "   - Lower (0.1-0.3): Job requirement lists, skill matching\n",
    "   - Medium (0.4-0.6): Job descriptions, company overviews\n",
    "   - Higher (0.7-0.9): Creative job titles, culture descriptions\n",
    "\n",
    "2. Top-p (Nucleus Sampling)\n",
    "   - Lower (0.1-0.3): Strict skill matching, technical requirements\n",
    "   - Medium (0.4-0.6): General job descriptions\n",
    "   - Higher (0.7-0.9): Diverse candidate suggestions\n",
    "\n",
    "3. Top-k\n",
    "   - Lower (10-20): Specific technical skills\n",
    "   - Medium (30-50): General job requirements\n",
    "   - Higher (50-100): Broad role descriptions\n",
    "\n",
    "4. Max Tokens\n",
    "   - Short (50-100): Job titles, quick summaries\n",
    "   - Medium (150-300): Job descriptions, candidate profiles\n",
    "   - Long (300+): Detailed analysis, full job postings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
