{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9a2d3b",
   "metadata": {},
   "source": [
    "# Max Tokens Parameter in LLMs\n",
    "\n",
    "## Introduction\n",
    "The max_tokens parameter controls the maximum length of the model's output in tokens. It acts as a safety limit to prevent unnecessarily long responses and helps manage computational resources.\n",
    "\n",
    "Key aspects:\n",
    "- **Token**: A piece of text (usually 3-4 characters in English)\n",
    "- **Default**: Usually model-specific (e.g., 2048 for many models)\n",
    "- **Range**: From 1 to model's context window size\n",
    "\n",
    "Understanding max_tokens is crucial for:\n",
    "- Controlling response length\n",
    "- Managing API costs\n",
    "- Ensuring consistent output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b187d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def query_ollama(prompt, max_tokens=100):\n",
    "    \"\"\"Query Ollama with a specific max_tokens setting\"\"\"\n",
    "    cmd = [\n",
    "        \"curl\",\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        \"-d\",\n",
    "        json.dumps({\n",
    "            \"model\": \"llama2\",\n",
    "            \"prompt\": prompt,\n",
    "            \"num_predict\": max_tokens  # Ollama uses num_predict for max_tokens\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    output, _ = process.communicate()\n",
    "\n",
    "    responses = [json.loads(line) for line in output.decode().strip().split(\"\\n\")]\n",
    "    return \"\".join(r.get(\"response\", \"\") for r in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8631c47",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Let's explore how different max_tokens values affect the model's output length. We'll use the same prompt with different token limits to demonstrate the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15315f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Tokens = 20 (Very brief)\n",
      "\n",
      "Neural networks are a type of machine learning algorithm that are designed to recognize patterns in data by mimicking the structure and function of the human brain. They consist of multiple layers of interconnected nodes or \"neurons,\" each of which processes a portion of the input data and passes the output to the next layer.\n",
      "\n",
      "Here's how a neural network works:\n",
      "\n",
      "1. Data Input: The network takes in a set of inputs, which could be images, sounds, text, or any other type of data.\n",
      "2. Forward Propagation: The inputs are passed through the network, layer by layer. Each layer consists of a set of neurons that process the input and pass it on to the next layer. The output of each neuron is calculated using a non-linear activation function, which introduces non-linearity to the network.\n",
      "3. Activation Function: The activation function is a mathematical function that takes the output of each neuron and maps it to a new value within a certain range. Commonly used activation functions include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
      "4. Backpropagation: The error between the predicted output and the actual output is calculated using a loss function such as mean squared error or cross-entropy. This error is then propagated backwards through the network, layer by layer, to calculate the gradients of the loss function with respect to each neuron's weights.\n",
      "5. Weight Update: The gradients are used to update the weights of each neuron using an optimization algorithm such as stochastic gradient descent (SGD) or Adam. The optimization algorithm iteratively adjusts the weights to minimize the loss function.\n",
      "6. Training: The network is trained on a large dataset of input-output pairs, and the weights are updated at each iteration until the network converges to an optimal set of weights that accurately predict the output for a given input.\n",
      "7. Deployment: Once the network is trained, it can be deployed in a production environment to perform tasks such as image classification, speech recognition, or natural language processing.\n",
      "\n",
      "Some key concepts in neural networks include:\n",
      "\n",
      "* Neurons: The basic building blocks of a neural network, which process inputs and pass them on to the next layer.\n",
      "* Layers: The different layers of a neural network, which can be organized into different types such as input, hidden, and output layers.\n",
      "* Activation Functions: Mathematical functions used to introduce non-linearity into the network, allowing it to learn more complex patterns in the data.\n",
      "* Weights: The parameters of the network that are adjusted during training to optimize the performance of the network.\n",
      "* Biases: constants added to the output of each neuron to shift the activation function's input range.\n",
      "* Optimization Algorithms: Techniques used to minimize the loss function and update the weights of the network, such as stochastic gradient descent (SGD) or Adam.\n",
      "\n",
      "In summary, a neural network works by taking in input data, applying multiple layers of non-linear transformations to it, using an activation function to introduce non-linearity, and updating the weights of the network through an optimization algorithm until it converges to an optimal set of weights that accurately predict the output for a given input.\n",
      "\n",
      "Max Tokens = 50 (Concise)\n",
      "\n",
      "Neural networks are a type of machine learning model that are inspired by the structure and function of the human brain. They are composed of interconnected nodes or \"neurons\" that process information and learn from experience. Here's a simplified explanation of how neural networks work:\n",
      "\n",
      "1. Input layer: The input layer receives the data or stimulus that the network will process. For example, if the network is designed to recognize images, this layer would contain the pixel values for an image.\n",
      "2. Hidden layers: One or more hidden layers are used to extract features from the input data. Each hidden layer contains a set of nodes (also called neurons) that apply non-linear transformations to the inputs they receive. The hidden layers allow the network to learn complex patterns in the data.\n",
      "3. Output layer: The output layer contains the nodes that produce the final output of the network, such as class labels or predictions. Each node in this layer applies a non-linear transformation to the output of the previous layer.\n",
      "4. Activation functions: Each node in the hidden and output layers uses an activation function to introduce non-linearity into the calculations. Common activation functions include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
      "5. Weight optimization: The nodes in the network are connected by edges, each of which has a weight associated with it. The weights are adjusted during training to minimize the error between the predicted output and the true output. This process is known as backpropagation.\n",
      "6. Training: During training, the network is presented with a large dataset of input-output pairs, and the weights are adjusted using an optimization algorithm such as stochastic gradient descent (SGD) or Adam. The goal is to minimize the loss function, which measures the difference between the predicted output and the true output.\n",
      "7. Testing: Once the network has been trained, it can be tested on new data to evaluate its performance. The output of the network is compared to the true output, and the accuracy of the predictions is calculated.\n",
      "\n",
      "In more detail, the processing in a neural network involves multiple layers of interconnected nodes (neurons), where each node applies a non-linear transformation to the input it receives. The output of each node is then passed to the next layer for further processing. The hidden layers allow the network to learn complex patterns in the data, and the output layer produces the final predictions or class labels.\n",
      "\n",
      "The training process involves minimizing the loss function between the predicted output and the true output using an optimization algorithm such as SGD or Adam. The optimization algorithm adjusts the weights of the network based on the gradient of the loss function with respect to the weights. This process is repeated multiple times until the network converges to a set of weights that result in accurate predictions.\n",
      "\n",
      "In summary, neural networks work by processing input data through multiple layers of interconnected nodes, using activation functions to introduce non-linearity, and adjusting the weights of the network during training to minimize the loss function between the predicted output and the true output.\n",
      "\n",
      "Max Tokens = 200 (Detailed)\n",
      "\n",
      "Neural networks are a type of machine learning model that are designed to recognize patterns in data by using artificial neurons to learn from experience. Here's a simplified explanation of how they work:\n",
      "\n",
      "1. Artificial Neurons: A neural network is composed of multiple layers of interconnected nodes (also called artificial neurons). Each node receives a set of inputs, performs a computation on those inputs, and sends the output to other nodes in the network.\n",
      "2. Learning Process: The nodes in the network are connected to each other through weights, which determine the strength of the connection between two nodes. During the training process, the network is presented with a dataset (inputs and outputs) and adjusts the weights to minimize the difference between the predicted output and the actual output.\n",
      "3. Forward Propagation: The network processes the inputs one layer at a time, starting from the input layer. Each node in the network applies a non-linear activation function to the weighted sum of its inputs, producing an output for that node. The output is then passed to the next layer for further processing.\n",
      "4. Backpropagation: The error between the predicted output and the actual output is calculated using a loss function, such as mean squared error or cross-entropy. The gradients of the loss function with respect to the weights are computed using backpropagation, which propagates the error backwards through the network, adjusting the weights at each layer to minimize the error.\n",
      "5. Optimization: The weights are updated using an optimization algorithm, such as stochastic gradient descent (SGD), to minimize the loss function. The optimization process is repeated until the network converges or reaches a desired level of accuracy.\n",
      "6. Generalization: Once the network is trained, it can be used to make predictions on new, unseen data. The network generalizes well to new data if the training data is representative of the problem domain and the network has learned useful features from the training data.\n",
      "7. Overfitting: Neural networks can suffer from overfitting, where the network becomes too complex and starts to fit the training noise rather than the underlying patterns. Techniques such as regularization, early stopping, or dropout help prevent overfitting by adding a penalty term to the loss function or by randomly setting some of the weights to zero during training.\n",
      "8. Activation Functions: Non-linear activation functions, such as sigmoid, tanh, and ReLU (Rectified Linear Unit), are used in the hidden layers of the network to introduce non-linearity and help the network learn more complex patterns. The choice of activation function depends on the problem domain and the desired output space.\n",
      "9. Pooling Layers: Pooling layers, such as max pooling or average pooling, are used to reduce the spatial dimensions of the input data, helping to capture fewer but more important features.\n",
      "10. Convolutional Layers: Convolutional layers use a small filter that slides over the input data, computing a dot product at each position to produce an output feature map. This allows the network to extract features that are shift-invariant and have a good spatial resolution.\n",
      "\n",
      "In summary, neural networks work by presenting the network with a dataset, adjusting the weights between nodes to minimize the difference between predicted outputs and actual outputs, and repeating this process until convergence or desired accuracy is reached. The architecture of the network, including the number of layers, activation functions, pooling layers, and convolutional layers, determines its ability to recognize patterns in data.\n"
     ]
    }
   ],
   "source": [
    "summary_prompt = \"Explain how neural networks work.\"\n",
    "\n",
    "print(\"Max Tokens = 20 (Very brief)\")\n",
    "print(query_ollama(summary_prompt, max_tokens=20))\n",
    "print(\"\\nMax Tokens = 50 (Concise)\")\n",
    "print(query_ollama(summary_prompt, max_tokens=50))\n",
    "print(\"\\nMax Tokens = 200 (Detailed)\")\n",
    "print(query_ollama(summary_prompt, max_tokens=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5806ed0",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Choose max_tokens based on your use case:\n",
    "\n",
    "1. **Short Responses (10-30 tokens)**\n",
    "   - Quick answers\n",
    "   - Single-sentence responses\n",
    "   - Command generation\n",
    "\n",
    "2. **Medium Responses (50-100 tokens)**\n",
    "   - Paragraphs\n",
    "   - Brief explanations\n",
    "   - Summaries\n",
    "\n",
    "3. **Long Responses (200+ tokens)**\n",
    "   - Detailed explanations\n",
    "   - Content generation\n",
    "   - Complex analysis\n",
    "\n",
    "**Tips:**\n",
    "- Always set max_tokens to prevent runaway generation\n",
    "- Consider token costs in production environments\n",
    "- Remember that max_tokens is an upper limit, not a target\n",
    "- Balance between completeness and conciseness\n",
    "- Account for different languages (some use more tokens per word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
